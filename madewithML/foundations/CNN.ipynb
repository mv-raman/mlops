{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/v0m01sk/Documents/1_code/personal/mlops/madewithML/foundations/made_with_ml_env/lib/python3.9/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/v0m01sk/Documents/1_code/personal/mlops/madewithML/foundations\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The New Faces of Reality TV</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  category\n",
       "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
       "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
       "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
       "3          Growing Signs of a Slowing on Wall Street  Business\n",
       "4                        The New Faces of Reality TV     World"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "url = \"datasets/news.csv\"\n",
    "df = pd.read_csv(url, header=0) # load\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/v0m01sk/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "print (STOPWORDS[:5])\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stopwords=STOPWORDS):\n",
    "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "    text = pattern.sub(\"\", text)\n",
    "\n",
    "    # Remove words in parenthesis\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)  # separate punctuation tied to words\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great week nyse'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "text = \"Great week for the NYSE!\"\n",
    "preprocess(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
      "\n",
      "sharon accepts plan reduce gaza army operation haaretz says\n"
     ]
    }
   ],
   "source": [
    "# Apply to dataframe\n",
    "preprocessed_df = df.copy()\n",
    "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
    "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size):\n",
    "    \"\"\"Split dataset into data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharon accepts plan reduce gaza army operation...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internet key battleground wildlife crime fight</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>july durable good orders rise 1 7 percent</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>growing signs slowing wall street</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new faces reality tv</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  category\n",
       "0  sharon accepts plan reduce gaza army operation...     World\n",
       "1     internet key battleground wildlife crime fight  Sci/Tech\n",
       "2          july durable good orders rise 1 7 percent  Business\n",
       "3                  growing signs slowing wall street  Business\n",
       "4                               new faces reality tv     World"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = preprocessed_df[\"title\"].values\n",
    "y = preprocessed_df[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84000,), y_train: (84000,)\n",
      "X_val: (18000,), y_val: (18000,)\n",
      "X_test: (18000,), y_test: (18000,)\n",
      "Sample point: china battles north korea nuclear talks → World\n"
     ]
    }
   ],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, train_size=TRAIN_SIZE)\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {'class_to_index': self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "NUM_CLASSES = len(label_encoder)\n",
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0]: World\n",
      "y_train[0]: 3\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = label_encoder.encode(y_train)\n",
    "y_val = label_encoder.encode(y_val)\n",
    "y_test = label_encoder.encode(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [21000 21000 21000 21000]\n",
      " weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print(f\"counts: {counts}\\n weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from more_itertools import take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, char_level, num_tokens=None,\n",
    "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
    "                 token_to_index=None):\n",
    "        self.char_level = char_level\n",
    "        self.separator = \"\" if self.char_level else \" \"\n",
    "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
    "        self.num_tokens = num_tokens\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        if not token_to_index:\n",
    "            token_to_index = {pad_token: 0, oov_token: 1}\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        if not self.char_level:\n",
    "            texts = [text.split(\" \") for text in texts]\n",
    "        all_tokens = [token for text in texts for token in text]\n",
    "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
    "        self.min_token_freq = counts[-1][1]\n",
    "        for token, count in counts:\n",
    "            index = len(self)\n",
    "            self.token_to_index[token] = index\n",
    "            self.index_to_token[index] = token\n",
    "        return self\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            if not self.char_level:\n",
    "                text = text.split(\" \")\n",
    "            sequence = []\n",
    "            for token in text:\n",
    "                sequence.append(self.token_to_index.get(\n",
    "                    token, self.token_to_index[self.oov_token]))\n",
    "            sequences.append(np.asarray(sequence))\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = []\n",
    "            for index in sequence:\n",
    "                text.append(self.index_to_token.get(index, self.oov_token))\n",
    "            texts.append(self.separator.join([token for token in text]))\n",
    "        return texts\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\n",
    "                \"char_level\": self.char_level,\n",
    "                \"oov_token\": self.oov_token,\n",
    "                \"token_to_index\": self.token_to_index\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=500)>\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = Tokenizer(char_level=False, num_tokens=500)\n",
    "tokenizer.fit_on_texts(texts=X_train)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print (tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4), ('lt', 5), ('us', 6), ('new', 7), ('oil', 8), ('says', 9)]\n",
      "least freq token's freq: 166\n"
     ]
    }
   ],
   "source": [
    "# Sample of tokens\n",
    "print (take(10, tokenizer.token_to_index.items()))\n",
    "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to indices:\n",
      "  (preprocessed) → china <UNK> north korea nuclear talks\n",
      "  (tokenized) → [ 16   1 285 142 114  24]\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences of indices\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
    "print (\"Text to indices:\\n\"\n",
    "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
    "    f\"  (tokenized) → {X_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(seq, num_classes):\n",
    "    \"\"\"One-hot encode a sequence of tokens.\"\"\"\n",
    "    one_hot = np.zeros((len(seq), num_classes))\n",
    "    for i, item in enumerate(seq):\n",
    "        one_hot[i, item] = 1.\n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16   1 285 142 114  24]\n",
      "6\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(6, 500)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "print (X_train[0])\n",
    "print (len(X_train[0]))\n",
    "cat = to_categorical(seq=X_train[0], num_classes=len(tokenizer))\n",
    "print (cat)\n",
    "print (cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert tokens to one-hot\n",
    "vocab_size = len(tokenizer)\n",
    "X_train = [to_categorical(seq, num_classes=vocab_size) for seq in X_train]\n",
    "X_val = [to_categorical(seq, num_classes=vocab_size) for seq in X_val]\n",
    "X_test = [to_categorical(seq, num_classes=vocab_size) for seq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84000, (5, 500))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_seq_len=0):\n",
    "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
    "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
    "    num_classes = sequences[0].shape[-1]\n",
    "    padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        padded_sequences[i][:len(sequence)] = sequence\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 500) (5, 500) (6, 500)\n",
      "(3, 6, 500)\n"
     ]
    }
   ],
   "source": [
    "# 3D sequences\n",
    "print (X_train[0].shape, X_train[1].shape, X_train[2].shape)\n",
    "padded = pad_sequences(X_train[0:3])\n",
    "print (padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, max_filter_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.max_filter_size = max_filter_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return [X, y]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Processing on a batch.\"\"\"\n",
    "        # Get inputs\n",
    "        batch = np.array(batch, dtype=object)\n",
    "        X = batch[:, 0]\n",
    "        y = np.stack(batch[:, 1], axis=0)\n",
    "\n",
    "        # Pad sequences\n",
    "        X = pad_sequences(X, max_seq_len=self.max_filter_size)\n",
    "\n",
    "        # Cast\n",
    "        X = torch.FloatTensor(X.astype(np.int32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train dataset:<Dataset(N=84000)>\n",
      "  Val dataset: <Dataset(N=18000)>\n",
      "  Test dataset: <Dataset(N=18000)>\n",
      "Sample point:\n",
      "  X: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "  y: 1\n"
     ]
    }
   ],
   "source": [
    "# Create datasets for embedding\n",
    "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=FILTER_SIZE)\n",
    "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=FILTER_SIZE)\n",
    "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=FILTER_SIZE)\n",
    "print (\"Datasets:\\n\"\n",
    "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
    "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
    "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {test_dataset[0][0]}\\n\"\n",
    "    f\"  y: {test_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: [64, 14, 500]\n",
      "  y: [64]\n",
      "Sample point:\n",
      "  X: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "  y: 1\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
    "batch_X, batch_y = next(iter(test_dataloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([64, 8, 10])\n",
      "X: torch.Size([64, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "# Assume all our inputs are padded to have the same # of words\n",
    "batch_size = 64\n",
    "max_seq_len = 8 # words per input\n",
    "vocab_size = 10 # one hot size\n",
    "x = torch.randn(batch_size, max_seq_len, vocab_size)\n",
    "print(f\"X: {x.shape}\")\n",
    "x = x.transpose(1, 2)\n",
    "print(f\"X: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "# Convolutional filters (VALID padding)\n",
    "vocab_size = 10 # one hot size\n",
    "num_filters = 50 # num filters\n",
    "filter_size = 3 # filters are 3X3\n",
    "stride = 1\n",
    "padding = 0 # valid padding (no padding)\n",
    "\n",
    "conv1 = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, kernel_size=filter_size, stride=stride, padding=padding, padding_mode='zeros')\n",
    "print(conv1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 8])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50, 6])\n"
     ]
    }
   ],
   "source": [
    "z = conv1(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: torch.Size([50, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "# Convolutional filters (SAME padding)\n",
    "vocab_size = 10 # one hot size\n",
    "num_filters = 50 # num filters\n",
    "filter_size = 3 # filters are 3X3\n",
    "stride = 1\n",
    "conv = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,\n",
    "                 kernel_size=filter_size, stride=stride)\n",
    "print(\"conv: {}\".format(conv.weight.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# `SAME` padding\n",
    "padding_left = int((conv.stride[0]*(max_seq_len-1) - max_seq_len + filter_size)/2)\n",
    "padding_right = int(math.ceil((conv.stride[0]*(max_seq_len-1) - max_seq_len + filter_size)/2))\n",
    "print (f\"padding: {(padding_left, padding_right)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: torch.Size([64, 50, 8])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "z = conv(F.pad(x, (padding_left, padding_right)))\n",
    "print (f\"z: {z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([64, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Max pooling\n",
    "pool_output = F.max_pool1d(z, z.size(2))\n",
    "print(\"Size: {}\".format(pool_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: torch.Size([64, 50, 6])\n"
     ]
    }
   ],
   "source": [
    "# Batch normalization\n",
    "batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
    "z = batch_norm(conv(x)) # applied to activations (after conv layer & before pooling)\n",
    "print (f\"z: {z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.01, std: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Mean and std before batchnorm\n",
    "print (f\"mean: {torch.mean(conv(x)):.2f}, std: {torch.std(conv(x)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.00, std: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Mean and std after batchnorm\n",
    "print (f\"mean: {torch.mean(z):.2f}, std: {torch.std(z):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model process:\n",
    "\n",
    "# a. We'll first tokenize the inputs (batch_size, max_seq_len)\n",
    "# b. then we will one hot encode the tokenized inputs (batch_size, max_seq_len, vocab_size)\n",
    "# c. then we apply convolution via filters (filter_size, vocab_size, num_filters)\n",
    "# d. 1d global max pooling\n",
    "# e. apply it to FC layer with dropout\n",
    "# f. FC layer with softmax to derive class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FILTERS = 50\n",
    "HIDDEN_DIM = 100\n",
    "DROPOUT_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, num_filters, filter_size,\n",
    "                 hidden_dim, dropout_p, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Convolutional filters\n",
    "        self.filter_size = filter_size\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=vocab_size, out_channels=num_filters,\n",
    "            kernel_size=filter_size, stride=1, padding=0, padding_mode=\"zeros\")\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
    "\n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs, channel_first=False,):\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        x_in, = inputs\n",
    "        if not channel_first:\n",
    "            x_in = x_in.transpose(1, 2)\n",
    "\n",
    "        # Padding for `SAME` padding\n",
    "        max_seq_len = x_in.shape[2]\n",
    "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
    "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
    "\n",
    "        # Conv outputs\n",
    "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
    "        z = F.max_pool1d(z, z.size(2)).squeeze(2)\n",
    "\n",
    "        # FC layer\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of CNN(\n",
      "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
      "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = CNN(vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
    "            hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 5\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, targets)  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "                batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                y_prob = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "    \n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.87803, val_loss: 0.79266, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 2 | train_loss: 0.78622, val_loss: 0.78657, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 3 | train_loss: 0.77814, val_loss: 0.78308, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 4 | train_loss: 0.77356, val_loss: 0.78323, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 5 | train_loss: 0.77004, val_loss: 0.78178, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 6 | train_loss: 0.76736, val_loss: 0.78176, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 7 | train_loss: 0.76481, val_loss: 0.78149, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 8 | train_loss: 0.76267, val_loss: 0.78138, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 9 | train_loss: 0.76129, val_loss: 0.78100, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 10 | train_loss: 0.75921, val_loss: 0.78103, lr: 1.00E-03, _patience: 4\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, classes):\n",
    "    \"\"\"Per-class performance metrics.\"\"\"\n",
    "    # Performance\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "\n",
    "    # Overall performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "\n",
    "    # Per-class performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"precision\": metrics[0][i],\n",
    "            \"recall\": metrics[1][i],\n",
    "            \"f1\": metrics[2][i],\n",
    "            \"num_samples\": np.float64(metrics[3][i]),\n",
    "        }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.7123467703902355,\n",
      "  \"recall\": 0.6938888888888889,\n",
      "  \"f1\": 0.6937218384036021,\n",
      "  \"num_samples\": 18000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "dir = Path(\"cnn\")\n",
    "dir.mkdir(parents=True, exist_ok=True)\n",
    "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
    "tokenizer.save(fp=Path(dir, 'tokenizer.json'))\n",
    "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
    "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
    "    json.dump(performance, indent=2, sort_keys=False, fp=fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_distribution(y_prob, classes):\n",
    "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
    "    results = {}\n",
    "    for i, class_ in enumerate(classes):\n",
    "        results[class_] = np.float64(y_prob[i])\n",
    "    sorted_results = {k: v for k, v in sorted(\n",
    "        results.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load artifacts\n",
    "device = torch.device(\"cpu\")\n",
    "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
    "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenizer.json'))\n",
    "model = CNN(\n",
    "    vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day new <UNK> stock market go <UNK>']\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "text = \"What a day for the new york stock market to go bust!\"\n",
    "sequences = tokenizer.texts_to_sequences([preprocess(text)])\n",
    "print (tokenizer.sequences_to_texts(sequences))\n",
    "X = [to_categorical(seq, num_classes=len(tokenizer)) for seq in sequences]\n",
    "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
    "dataset = Dataset(X=X, y=y_filler, max_filter_size=FILTER_SIZE)\n",
    "dataloader = dataset.create_dataloader(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "y_prob = trainer.predict_step(dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "label_encoder.decode(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Business\": 3.016254425048828,\n",
      "  \"Sci/Tech\": 0.9771913886070251,\n",
      "  \"World\": -0.9979062080383301,\n",
      "  \"Sports\": -2.8599812984466553\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Class distributions\n",
    "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
    "print (json.dumps(prob_dist, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_val = {\n",
    "  \"Business\": 3.016254425048828,\n",
    "  \"Sci/Tech\": 0.9771913886070251,\n",
    "  \"World\": -0.9979062080383301,\n",
    "  \"Sports\": -2.8599812984466553\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86879914, 0.11307473, 0.01568887, 0.00243726])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.array(list(dictionary_val.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprtability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpretableCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, num_filters, filter_size,\n",
    "                 hidden_dim, dropout_p, num_classes):\n",
    "        super(InterpretableCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional filters\n",
    "        self.filter_size = filter_size\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=vocab_size, out_channels=num_filters, \n",
    "            kernel_size=filter_size, stride=1, padding=0, padding_mode='zeros')\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
    "\n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs, channel_first=False, apply_softmax=False):\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        x_in, = inputs\n",
    "        if not channel_first:\n",
    "            x_in = x_in.transpose(1, 2)\n",
    "\n",
    "        # Padding for `SAME` padding\n",
    "        max_seq_len = x_in.shape[2]\n",
    "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
    "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
    "\n",
    "        # Conv outputs\n",
    "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "interpretable_model = InterpretableCNN(\n",
    "    vocab_size=len(tokenizer), num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InterpretableCNN(\n",
       "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights (same architecture)\n",
    "interpretable_model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
    "interpretable_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "interpretable_trainer = Trainer(model=interpretable_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7)\n"
     ]
    }
   ],
   "source": [
    "# Get conv outputs\n",
    "conv_outputs = interpretable_trainer.predict_step(dataloader)\n",
    "print (conv_outputs.shape) # (num_filters, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a bi-gram filter's outputs\n",
    "tokens = tokenizer.sequences_to_texts(sequences)[0].split(' ')\n",
    "sns.heatmap(conv_outputs, xticklabels=tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filters have high values for the words `stock` and `market` which influenced the `Business` category classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "made_with_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
