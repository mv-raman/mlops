{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/v0m01sk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\");\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15640 sentences\n"
     ]
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "book = open(\"datasets/harrypotter.txt\",encoding='ISO-8859-1')\n",
    "sentences = tokenizer.tokenize(str(book.read()))\n",
    "print (f\"{len(sentences)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"Conditional preprocessing on our text.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # Separate into word tokens\n",
    "    text = text.split(\" \")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snape nodded, but did not elaborate.\n",
      "['snape', 'nodded', 'but', 'did', 'not', 'elaborate']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess sentences\n",
    "print (sentences[11])\n",
    "sentences = [preprocess(sentence) for sentence in sentences]\n",
    "print (sentences[11])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "WINDOW = 5\n",
    "MIN_COUNT = 3 # Ignores all words with total frequency lower than this\n",
    "SKIP_GRAM = 1 # 0 = CBOW\n",
    "NEGATIVE_SAMPLING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=4836, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Super fast because of optimized C code under the hood\n",
    "w2v = Word2Vec(\n",
    "    sentences=sentences, vector_size=EMBEDDING_DIM,\n",
    "    window=WINDOW, min_count=MIN_COUNT,\n",
    "    sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n",
    "print (w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12699352, -0.17945859, -0.02842927,  0.18085366,  0.39401197,\n",
       "       -0.23843837,  0.10709333,  0.22894466, -0.26733428, -0.42368442,\n",
       "       -0.2703049 , -0.3565948 ,  0.10423029, -0.08112939,  0.25583032,\n",
       "       -0.22773156, -0.11745971, -0.08729629,  0.02723035, -0.77030116,\n",
       "        0.03699608, -0.11432514, -0.04923914, -0.37714446, -0.02621232,\n",
       "       -0.01370691,  0.08995658,  0.01133524, -0.08143893,  0.4417435 ,\n",
       "       -0.00973469, -0.06981888,  0.11526221, -0.04953983, -0.13826434,\n",
       "       -0.02830129, -0.04691692, -0.2543932 ,  0.07128965, -0.20294228,\n",
       "        0.392661  , -0.40073213, -0.08232796,  0.23154454,  0.3641323 ,\n",
       "       -0.13340057,  0.32479513, -0.2448636 ,  0.32145348,  0.11059126,\n",
       "        0.43174803, -0.16449459,  0.4753074 , -0.2452044 , -0.19191335,\n",
       "        0.09374887, -0.43624127,  0.25794244, -0.4029199 ,  0.0149832 ,\n",
       "        0.19034143,  0.09080013,  0.13090806,  0.06975318, -0.34754243,\n",
       "        0.556014  ,  0.38723427,  0.26847625, -0.13998124,  0.45093372,\n",
       "       -0.5438428 ,  0.55282956,  0.27078047, -0.13540466,  0.06422494,\n",
       "        0.07820586,  0.36166888, -0.14783137,  0.33702675, -0.27215245,\n",
       "       -0.00941035,  0.07660858, -0.25183073,  0.32212597, -0.07464044,\n",
       "       -0.23246078,  0.00887306,  0.11942446,  0.3614656 ,  0.06080487,\n",
       "        0.18874487,  0.15637697, -0.09049188,  0.12018185,  0.32581517,\n",
       "        0.00712809, -0.02228346, -0.16246262,  0.36245465, -0.24654478],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector for each word\n",
    "w2v.wv.get_vector(\"potter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving and loading\n",
    "w2v.wv.save_word2vec_format(\"model.bin\", binary=True)\n",
    "w2v = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=4836, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# Super fast because of optimized C code under the hood\n",
    "ft = FastText(sentences=sentences, vector_size=EMBEDDING_DIM,\n",
    "              window=WINDOW, min_count=MIN_COUNT,\n",
    "              sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n",
    "print (ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This word doesn't exist so the word2vec model will error out\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mw2v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscarring\u001b[39m\u001b[38;5;124m\"\u001b[39m, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "# This word doesn't exist so the word2vec model will error out\n",
    "w2v.wv.most_similar(positive=\"scarring\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('swimming', 0.9932186603546143),\n",
       " ('bulging', 0.9926645159721375),\n",
       " ('dabbing', 0.992368221282959),\n",
       " ('dueling', 0.9923586249351501),\n",
       " ('building', 0.9923309683799744)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastText will use n-grams to embed an OOV word\n",
    "ft.wv.most_similar(positive=\"scarring\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and loading\n",
    "ft.wv.save(\"model.bin\")\n",
    "ft = KeyedVectors.load(\"model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "EMBEDDING_DIM = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(words, embeddings, pca_results):\n",
    "    for word in words:\n",
    "        index = embeddings.index2word.index(word)\n",
    "        plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
    "        plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unzip the file (may take ~3-5 minutes)\n",
    "# resp = urlopen(\"http://nlp.stanford.edu/data/glove.6B.zip\")\n",
    "# zipfile = ZipFile(BytesIO(resp.read()))\n",
    "# zipfile.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write embeddings to file\n",
    "embeddings_file = \"glove.6B.{0}d.txt\".format(EMBEDDING_DIM)\n",
    "# zipfile.extract(embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: the\n",
      "embedding:\n",
      "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n",
      "embedding dim: 100\n"
     ]
    }
   ],
   "source": [
    "# Preview of the GloVe embeddings file\n",
    "with open(embeddings_file, \"r\") as fp:\n",
    "    line = next(fp)\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embedding = np.asarray(values[1:], dtype='float32')\n",
    "    print (f\"word: {word}\")\n",
    "    print (f\"embedding:\\n{embedding}\")\n",
    "    print (f\"embedding dim: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/3028217428.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(embeddings_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save GloVe embeddings to local directory in word2vec format\n",
    "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\n",
    "glove2word2vec(embeddings_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings (may take a minute)\n",
    "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380331993103),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (king - man) + woman = ?\n",
    "# king - man = ? -  woman\n",
    "glove.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gohan', 0.7246543169021606),\n",
       " ('bulma', 0.6497019529342651),\n",
       " ('raistlin', 0.644360363483429),\n",
       " ('skaar', 0.6316742897033691),\n",
       " ('guybrush', 0.6231324672698975)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nearest neighbors (excluding itself)\n",
    "glove.most_similar(positive=\"goku\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = glove[glove.key_to_index.keys()]\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(words, embeddings, pca_results):\n",
    "    for word in words:\n",
    "        index = embeddings.index_to_key.index(word)\n",
    "        plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
    "        plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_embeddings(\n",
    "    words=[\"king\", \"queen\", \"man\", \"woman\"], embeddings=glove,\n",
    "    pca_results=pca_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.7735227942466736),\n",
       " ('physician', 0.7189430594444275),\n",
       " ('doctors', 0.6824327707290649),\n",
       " ('patient', 0.6750682592391968),\n",
       " ('dentist', 0.6726033091545105)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bias in embeddings\n",
    "glove.most_similar(positive=[\"woman\", \"doctor\"], negative=[\"man\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/2088852160.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/v0m01sk/Documents/1_code/personal/mlops/madewithML/foundations/made_with_ml_env/lib/python3.9/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The New Faces of Reality TV</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  category\n",
       "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
       "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
       "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
       "3          Growing Signs of a Slowing on Wall Street  Business\n",
       "4                        The New Faces of Reality TV     World"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "url = \"datasets/news.csv\"\n",
    "df = pd.read_csv(url, header=0) # load\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/v0m01sk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "print (STOPWORDS[:5])\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stopwords=STOPWORDS):\n",
    "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "    text = pattern.sub(\"\", text)\n",
    "\n",
    "    # Remove words in parenthesis\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great week nyse'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "text = \"Great week for the NYSE!\"\n",
    "preprocess(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
      "\n",
      "sharon accepts plan reduce gaza army operation haaretz says\n"
     ]
    }
   ],
   "source": [
    "# Apply to dataframe\n",
    "preprocessed_df = df.copy()\n",
    "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
    "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size):\n",
    "    \"\"\"Split dataset into data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = preprocessed_df[\"title\"].values\n",
    "y = preprocessed_df[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84000,), y_train: (84000,)\n",
      "X_val: (18000,), y_val: (18000,)\n",
      "X_test: (18000,), y_test: (18000,)\n",
      "Sample point: china battles north korea nuclear talks → World\n"
     ]
    }
   ],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, train_size=TRAIN_SIZE)\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {'class_to_index': self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "NUM_CLASSES = len(label_encoder)\n",
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0]: World\n",
      "y_train[0]: 3\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = label_encoder.encode(y_train)\n",
    "y_val = label_encoder.encode(y_val)\n",
    "y_test = label_encoder.encode(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [21000 21000 21000 21000]\n",
      "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"counts: {counts}\\nweights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from more_itertools import take\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, char_level, num_tokens=None,\n",
    "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
    "                 token_to_index=None):\n",
    "        self.char_level = char_level\n",
    "        self.separator = \"\" if self.char_level else \" \"\n",
    "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
    "        self.num_tokens = num_tokens\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        if not token_to_index:\n",
    "            token_to_index = {pad_token: 0, oov_token: 1}\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        if not self.char_level:\n",
    "            texts = [text.split(\" \") for text in texts]\n",
    "        all_tokens = [token for text in texts for token in text]\n",
    "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
    "        self.min_token_freq = counts[-1][1]\n",
    "        for token, count in counts:\n",
    "            index = len(self)\n",
    "            self.token_to_index[token] = index\n",
    "            self.index_to_token[index] = token\n",
    "        return self\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            if not self.char_level:\n",
    "                text = text.split(\" \")\n",
    "            sequence = []\n",
    "            for token in text:\n",
    "                sequence.append(self.token_to_index.get(\n",
    "                    token, self.token_to_index[self.oov_token]))\n",
    "            sequences.append(np.asarray(sequence))\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = []\n",
    "            for index in sequence:\n",
    "                text.append(self.index_to_token.get(index, self.oov_token))\n",
    "            texts.append(self.separator.join([token for token in text]))\n",
    "        return texts\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\n",
    "                \"char_level\": self.char_level,\n",
    "                \"oov_token\": self.oov_token,\n",
    "                \"token_to_index\": self.token_to_index\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=5000)>\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
    "tokenizer.fit_on_texts(texts=X_train)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print (tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
      "least freq token's freq: 14\n"
     ]
    }
   ],
   "source": [
    "# Sample of tokens\n",
    "print (take(5, tokenizer.token_to_index.items()))\n",
    "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to indices:\n",
      "  (preprocessed) → china battles north korea nuclear talks\n",
      "  (tokenized) → [  16 1491  285  142  114   24]\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences of indices\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
    "print (\"Text to indices:\\n\"\n",
    "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
    "    f\"  (tokenized) → {X_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 1, 6, 5, 6]])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "vocab_size=10\n",
    "x = torch.randint(high=vocab_size, size=(1,5))\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "embeddings = nn.Embedding(embedding_dim=100,\n",
    "                          num_embeddings=vocab_size)\n",
    "print(embeddings.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 100])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_seq_len=0):\n",
    "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
    "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
    "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        padded_sequences[i][:len(sequence)] = sequence\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "[[1.600e+01 1.491e+03 2.850e+02 1.420e+02 1.140e+02 2.400e+01]\n",
      " [1.445e+03 2.300e+01 6.560e+02 2.197e+03 1.000e+00 0.000e+00]\n",
      " [1.200e+02 1.400e+01 1.955e+03 1.005e+03 1.529e+03 4.014e+03]]\n"
     ]
    }
   ],
   "source": [
    "# 2D sequences\n",
    "padded = pad_sequences(X_train[0:3])\n",
    "print (padded.shape)\n",
    "print (padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, max_filter_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.max_filter_size = max_filter_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return [X, y]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Processing on a batch.\"\"\"\n",
    "        # Get inputs\n",
    "        batch = np.array(batch, dtype=object)\n",
    "        X = batch[:, 0]\n",
    "        y = np.stack(batch[:, 1], axis=0)\n",
    "\n",
    "        # Pad sequences\n",
    "        X = pad_sequences(X)\n",
    "\n",
    "        # Cast\n",
    "        X = torch.LongTensor(X.astype(np.int32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train dataset:<Dataset(N=84000)>\n",
      "  Val dataset: <Dataset(N=18000)>\n",
      "  Test dataset: <Dataset(N=18000)>\n",
      "Sample point:\n",
      "  X: [  16 1491  285  142  114   24]\n",
      "  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "max_filter_size = max(FILTER_SIZES)\n",
    "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\n",
    "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\n",
    "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\n",
    "print (\"Datasets:\\n\"\n",
    "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
    "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
    "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {train_dataset[0][0]}\\n\"\n",
    "    f\"  y: {train_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: [64, 14]\n",
      "  y: [64]\n",
      "Sample point:\n",
      "  X: tensor([  16, 1491,  285,  142,  114,   24,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      "  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 100\n",
    "DROPOUT_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
    "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
    "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
    "                 padding_idx=0):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Filter sizes\n",
    "        self.filter_sizes = filter_sizes\n",
    "\n",
    "        # Initialize embeddings\n",
    "        if pretrained_embeddings is None:\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx)\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
    "\n",
    "        # Freeze embeddings or not\n",
    "        if freeze_embeddings:\n",
    "            self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        # Conv weights\n",
    "        self.conv = nn.ModuleList(\n",
    "            [nn.Conv1d(in_channels=embedding_dim,\n",
    "                       out_channels=num_filters,\n",
    "                       kernel_size=f) for f in filter_sizes])\n",
    "\n",
    "        # FC weights\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs, channel_first=False):\n",
    "\n",
    "        # Embed\n",
    "        x_in, = inputs\n",
    "        x_in = self.embeddings(x_in)\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        if not channel_first:\n",
    "            x_in = x_in.transpose(1, 2)\n",
    "\n",
    "        # Conv outputs\n",
    "        z = []\n",
    "        max_seq_len = x_in.shape[2]\n",
    "        for i, f in enumerate(self.filter_sizes):\n",
    "            # `SAME` padding\n",
    "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
    "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
    "\n",
    "            # Conv + pool\n",
    "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
    "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
    "            z.append(_z)\n",
    "\n",
    "        # Concat conv outputs\n",
    "        z = torch.cat(z, 1)\n",
    "\n",
    "        # FC layers\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(embeddings_file):\n",
    "    \"\"\"Load embeddings from a file.\"\"\"\n",
    "    embeddings = {}\n",
    "    with open(embeddings_file, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = embedding\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\n",
    "    \"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\n",
    "    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Embeddings(words=5000, dim=100)>\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings_file = 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
    "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
    "embedding_matrix = make_embeddings_matrix(\n",
    "    embeddings=glove_embeddings, word_index=tokenizer.token_to_index,\n",
    "    embedding_dim=EMBEDDING_DIM)\n",
    "print (f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialized embeddings (fine-tuned)\n",
    "# GloVe embeddings (frozen)\n",
    "# GloVe embeddings (fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FILTERS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 5\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, targets)  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "                batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "\n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, classes):\n",
    "    \"\"\"Per-class performance metrics.\"\"\"\n",
    "    # Performance\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "\n",
    "    # Overall performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "\n",
    "    # Per-class performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"precision\": metrics[0][i],\n",
    "            \"recall\": metrics[1][i],\n",
    "            \"f1\": metrics[2][i],\n",
    "            \"num_samples\": np.float64(metrics[3][i]),\n",
    "        }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Random Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBEDDINGS = None\n",
    "FREEZE_EMBEDDINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of CNN(\n",
      "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
      "  (conv): ModuleList(\n",
      "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
      "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
      "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = CNN(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
    "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.76771, val_loss: 0.59960, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 2 | train_loss: 0.49467, val_loss: 0.56995, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 3 | train_loss: 0.40616, val_loss: 0.59464, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 4 | train_loss: 0.34672, val_loss: 0.61629, lr: 1.00E-03, _patience: 3\n",
      "Epoch: 5 | train_loss: 0.29819, val_loss: 0.65467, lr: 1.00E-03, _patience: 2\n",
      "Epoch: 6 | train_loss: 0.25764, val_loss: 0.68787, lr: 1.00E-04, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8129603024669748,\n",
      "  \"recall\": 0.8116111111111111,\n",
      "  \"f1\": 0.8120434581231313,\n",
      "  \"num_samples\": 18000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.  Glove frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
    "FREEZE_EMBEDDINGS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of CNN(\n",
      "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
      "  (conv): ModuleList(\n",
      "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
      "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
      "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = CNN(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
    "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.51481, val_loss: 0.47758, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 2 | train_loss: 0.44086, val_loss: 0.46504, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 3 | train_loss: 0.41160, val_loss: 0.46613, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 4 | train_loss: 0.38803, val_loss: 0.47267, lr: 1.00E-03, _patience: 3\n",
      "Epoch: 5 | train_loss: 0.36885, val_loss: 0.48240, lr: 1.00E-03, _patience: 2\n",
      "Epoch: 6 | train_loss: 0.35272, val_loss: 0.49369, lr: 1.00E-04, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.832625657783757,\n",
      "  \"recall\": 0.8326111111111111,\n",
      "  \"f1\": 0.8324252996800303,\n",
      "  \"num_samples\": 18000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.glove(fine tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
    "FREEZE_EMBEDDINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of CNN(\n",
      "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
      "  (conv): ModuleList(\n",
      "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
      "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
      "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = CNN(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
    "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.48896, val_loss: 0.44544, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 2 | train_loss: 0.39139, val_loss: 0.44009, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 3 | train_loss: 0.34597, val_loss: 0.45736, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 4 | train_loss: 0.30353, val_loss: 0.49066, lr: 1.00E-03, _patience: 3\n",
      "Epoch: 5 | train_loss: 0.25908, val_loss: 0.55018, lr: 1.00E-03, _patience: 2\n",
      "Epoch: 6 | train_loss: 0.21547, val_loss: 0.63128, lr: 1.00E-04, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8278757231947823,\n",
      "  \"recall\": 0.8276111111111111,\n",
      "  \"f1\": 0.827694225221748,\n",
      "  \"num_samples\": 18000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "from pathlib import Path\n",
    "dir = Path(\"cnn\")\n",
    "dir.mkdir(parents=True, exist_ok=True)\n",
    "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
    "tokenizer.save(fp=Path(dir, \"tokenizer.json\"))\n",
    "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
    "with open(Path(dir, \"performance.json\"), \"w\") as fp:\n",
    "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_distribution(y_prob, classes):\n",
    "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
    "    results = {}\n",
    "    for i, class_ in enumerate(classes):\n",
    "        results[class_] = np.float64(y_prob[i])\n",
    "    sorted_results = {k: v for k, v in sorted(\n",
    "        results.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
       "  (conv): ModuleList(\n",
       "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
       "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
       "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load artifacts\n",
    "device = torch.device(\"cpu\")\n",
    "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
    "tokenizer = Tokenizer.load(fp=Path(dir, \"tokenizer.json\"))\n",
    "model = CNN(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
    "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
    "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['final tennis tournament starts next week']\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "text = \"The final tennis tournament starts next week.\"\n",
    "X = tokenizer.texts_to_sequences([preprocess(text)])\n",
    "print (tokenizer.sequences_to_texts(X))\n",
    "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
    "dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)\n",
    "dataloader = dataset.create_dataloader(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_1931/4106836722.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sports']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "y_prob = trainer.predict_step(dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sports\": 1.0,\n",
      "  \"World\": 5.2038581777047455e-12,\n",
      "  \"Sci/Tech\": 1.5110102839083206e-12,\n",
      "  \"Business\": 1.1102017429223568e-15\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Class distributions\n",
    "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
    "print (json.dumps(prob_dist, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpretableCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
    "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
    "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
    "                 padding_idx=0):\n",
    "        super(InterpretableCNN, self).__init__()\n",
    "\n",
    "        # Filter sizes\n",
    "        self.filter_sizes = filter_sizes\n",
    "\n",
    "        # Initialize embeddings\n",
    "        if pretrained_embeddings is None:\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx)\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.embeddings = nn.Embedding(\n",
    "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
    "\n",
    "        # Freeze embeddings or not\n",
    "        if freeze_embeddings:\n",
    "            self.embeddings.weight.requires_grad = False\n",
    "\n",
    "        # Conv weights\n",
    "        self.conv = nn.ModuleList(\n",
    "            [nn.Conv1d(in_channels=embedding_dim,\n",
    "                       out_channels=num_filters,\n",
    "                       kernel_size=f) for f in filter_sizes])\n",
    "\n",
    "        # FC weights\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs, channel_first=False):\n",
    "\n",
    "        # Embed\n",
    "        x_in, = inputs\n",
    "        x_in = self.embeddings(x_in)\n",
    "\n",
    "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
    "        if not channel_first:\n",
    "            x_in = x_in.transpose(1, 2)\n",
    "\n",
    "        # Conv outputs\n",
    "        z = []\n",
    "        max_seq_len = x_in.shape[2]\n",
    "        for i, f in enumerate(self.filter_sizes):\n",
    "            # `SAME` padding\n",
    "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
    "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
    "\n",
    "            # Conv + pool\n",
    "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
    "            z.append(_z.cpu().numpy())\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
    "FREEZE_EMBEDDINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InterpretableCNN(\n",
       "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
       "  (conv): ModuleList(\n",
       "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
       "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
       "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "interpretable_model = InterpretableCNN(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
    "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
    "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
    "interpretable_model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
    "interpretable_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Get conv outputs\n",
    "interpretable_model.eval()\n",
    "conv_outputs = []\n",
    "with torch.inference_mode():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Forward pass w/ inputs\n",
    "        inputs, targets = batch[:-1], batch[-1]\n",
    "        z = interpretable_model(inputs)\n",
    "\n",
    "        # Store conv outputs\n",
    "        conv_outputs.extend(z)\n",
    "\n",
    "conv_outputs = np.vstack(conv_outputs)\n",
    "print (conv_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a bi-gram filter's outputs\n",
    "tokens = tokenizer.sequences_to_texts(X)[0].split(\" \")\n",
    "filter_size = 2\n",
    "# sns.heatmap(conv_outputs[filter_size-1][:, len(tokens)-1], xticklabels=tokens)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "The final tennis tournament starts next week.\n",
      "\n",
      "Preprocessed text:\n",
      "final tennis tournament starts next week\n",
      "\n",
      "Most important n-grams:\n",
      "[1-gram]: tennis\n",
      "[2-gram]: tennis tournament\n",
      "[3-gram]: final tennis tournament\n"
     ]
    }
   ],
   "source": [
    "sample_index = 0\n",
    "print (f\"Original text:\\n{text}\")\n",
    "print (f\"\\nPreprocessed text:\\n{tokenizer.sequences_to_texts(X)[0]}\")\n",
    "print (\"\\nMost important n-grams:\")\n",
    "# Process conv outputs for each unique filter size\n",
    "for i, filter_size in enumerate(FILTER_SIZES):\n",
    "\n",
    "    # Identify most important n-gram (excluding last token)\n",
    "    popular_indices = collections.Counter([np.argmax(conv_output) \\\n",
    "            for conv_output in conv_outputs[i]])\n",
    "\n",
    "    # Get corresponding text\n",
    "    start = popular_indices.most_common(1)[-1][0]\n",
    "    n_gram = \" \".join([token for token in tokens[start:start+filter_size]])\n",
    "    print (f\"[{filter_size}-gram]: {n_gram}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "made_with_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
