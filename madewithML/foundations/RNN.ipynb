{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_70056/2504337499.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/v0m01sk/Documents/1_code/personal/mlops/madewithML/foundations/made_with_ml_env/lib/python3.9/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The New Faces of Reality TV</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  category\n",
       "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
       "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
       "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
       "3          Growing Signs of a Slowing on Wall Street  Business\n",
       "4                        The New Faces of Reality TV     World"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "url = \"datasets/news.csv\"\n",
    "df = pd.read_csv(url, header=0) # load\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/v0m01sk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "print (STOPWORDS[:5])\n",
    "porter = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stopwords=STOPWORDS):\n",
    "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "    text = pattern.sub(\"\", text)\n",
    "\n",
    "    # Remove words in parenthesis\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great week nyse'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "text = \"Great week for the NYSE!\"\n",
    "preprocess(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
      "\n",
      "sharon accepts plan reduce gaza army operation haaretz says\n"
     ]
    }
   ],
   "source": [
    "# Apply to dataframe\n",
    "preprocessed_df = df.copy()\n",
    "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
    "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size):\n",
    "    \"\"\"Split dataset into data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = preprocessed_df[\"title\"].values\n",
    "y = preprocessed_df[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (84000,), y_train: (84000,)\n",
      "X_val: (18000,), y_val: (18000,)\n",
      "X_test: (18000,), y_test: (18000,)\n",
      "Sample point: china battles north korea nuclear talks → World\n"
     ]
    }
   ],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, train_size=TRAIN_SIZE)\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {'class_to_index': self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "NUM_CLASSES = len(label_encoder)\n",
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0]: World\n",
      "y_train[0]: 3\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = label_encoder.encode(y_train)\n",
    "y_val = label_encoder.encode(y_val)\n",
    "y_test = label_encoder.encode(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [21000 21000 21000 21000]\n",
      "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"counts: {counts}\\nweights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from more_itertools import take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, char_level, num_tokens=None,\n",
    "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
    "                 token_to_index=None):\n",
    "        self.char_level = char_level\n",
    "        self.separator = \"\" if self.char_level else \" \"\n",
    "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
    "        self.num_tokens = num_tokens\n",
    "        self.pad_token = pad_token\n",
    "        self.oov_token = oov_token\n",
    "        if not token_to_index:\n",
    "            token_to_index = {pad_token: 0, oov_token: 1}\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        if not self.char_level:\n",
    "            texts = [text.split(\" \") for text in texts]\n",
    "        all_tokens = [token for text in texts for token in text]\n",
    "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
    "        self.min_token_freq = counts[-1][1]\n",
    "        for token, count in counts:\n",
    "            index = len(self)\n",
    "            self.token_to_index[token] = index\n",
    "            self.index_to_token[index] = token\n",
    "        return self\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            if not self.char_level:\n",
    "                text = text.split(\" \")\n",
    "            sequence = []\n",
    "            for token in text:\n",
    "                sequence.append(self.token_to_index.get(\n",
    "                    token, self.token_to_index[self.oov_token]))\n",
    "            sequences.append(np.asarray(sequence))\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = []\n",
    "            for index in sequence:\n",
    "                text.append(self.index_to_token.get(index, self.oov_token))\n",
    "            texts.append(self.separator.join([token for token in text]))\n",
    "        return texts\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\n",
    "                \"char_level\": self.char_level,\n",
    "                \"oov_token\": self.oov_token,\n",
    "                \"token_to_index\": self.token_to_index\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tokenizer(num_tokens=5000)>\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
    "tokenizer.fit_on_texts(texts=X_train)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "print (tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
      "least freq token's freq: 14\n"
     ]
    }
   ],
   "source": [
    "# Sample of tokens\n",
    "print (take(5, tokenizer.token_to_index.items()))\n",
    "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to indices:\n",
      "  (preprocessed) → china battles north korea nuclear talks\n",
      "  (tokenized) → [  16 1491  285  142  114   24]\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences of indices\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
    "print (\"Text to indices:\\n\"\n",
    "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
    "    f\"  (tokenized) → {X_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_seq_len=0):\n",
    "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
    "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
    "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        padded_sequences[i][:len(sequence)] = sequence\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "[[1.600e+01 1.491e+03 2.850e+02 1.420e+02 1.140e+02 2.400e+01]\n",
      " [1.445e+03 2.300e+01 6.560e+02 2.197e+03 1.000e+00 0.000e+00]\n",
      " [1.200e+02 1.400e+01 1.955e+03 1.005e+03 1.529e+03 4.014e+03]]\n"
     ]
    }
   ],
   "source": [
    "# 2D sequences\n",
    "padded = pad_sequences(X_train[0:3])\n",
    "print (padded.shape)\n",
    "print (padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, max_filter_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.max_filter_size = max_filter_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return [X, len(X), y]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Processing on a batch.\"\"\"\n",
    "        # Get inputs\n",
    "        batch = np.array(batch, dtype=object)\n",
    "        X = batch[:, 0]\n",
    "        seq_lens = batch[:, 1]\n",
    "        y = np.stack(batch[:, 2], axis=0)\n",
    "\n",
    "        # Pad inputs\n",
    "        X = pad_sequences(sequences=X)\n",
    "\n",
    "        # Cast\n",
    "        X = torch.LongTensor(X.astype(np.int32))\n",
    "        seq_lens = torch.LongTensor(seq_lens.astype(np.int32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "\n",
    "        return X, seq_lens, y\n",
    "\n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train dataset:<Dataset(N=84000)>\n",
      "  Val dataset: <Dataset(N=18000)>\n",
      "  Test dataset: <Dataset(N=18000)>\n",
      "Sample point:\n",
      "  X: [  16 1491  285  142  114   24]\n",
      "  seq_len: 6\n",
      "  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "max_filter_size = max(FILTER_SIZES)\n",
    "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\n",
    "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\n",
    "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\n",
    "print (\"Datasets:\\n\"\n",
    "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
    "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
    "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {train_dataset[0][0]}\\n\"\n",
    "    f\"  seq_len: {train_dataset[0][1]}\\n\"\n",
    "    f\"  y: {train_dataset[0][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: [64, 14]\n",
      "  seq_lens: [64]\n",
      "  y: [64]\n",
      "Sample point:\n",
      "  X: tensor([  16, 1491,  285,  142,  114,   24,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      " seq_len: 6\n",
      "  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(\n",
    "    batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(\n",
    "    batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(\n",
    "    batch_size=batch_size)\n",
    "batch_X, batch_seq_lens, batch_y = next(iter(train_dataloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  seq_lens: {list(batch_seq_lens.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\" seq_len: {batch_seq_lens[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, targets)  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "                batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "\n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8, 100])\n",
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "sequence_size = 8 # words per input\n",
    "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
    "seq_lens = torch.randint(high=sequence_size, size=(1, BATCH_SIZE))\n",
    "print (x.shape)\n",
    "print (seq_lens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_HIDDEN_DIM = 128\n",
    "DROPOUT_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "# Initialize hidden state\n",
    "hidden_t = torch.zeros((BATCH_SIZE, RNN_HIDDEN_DIM))\n",
    "print (hidden_t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNCell(100, 128)\n"
     ]
    }
   ],
   "source": [
    "# Initialize RNN cell\n",
    "rnn_cell = nn.RNNCell(EMBEDDING_DIM, RNN_HIDDEN_DIM)\n",
    "print (rnn_cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 100])\n",
      "torch.Size([64, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass through RNN\n",
    "x = x.permute(1, 0, 2) # RNN needs batch_size to be at dim 1\n",
    "print(x.shape)\n",
    "# Loop through the inputs time steps\n",
    "hiddens = []\n",
    "for t in range(sequence_size):\n",
    "    hidden_t = rnn_cell(x[t], hidden_t)\n",
    "    hiddens.append(hidden_t)\n",
    "hiddens = torch.stack(hiddens)\n",
    "hiddens = hiddens.permute(1, 0, 2) # bring batch_size back to dim 0\n",
    "print (hiddens.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([64, 8, 128])\n",
      "h_n: torch.Size([1, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "# We also could've used a more abstracted layer\n",
    "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
    "rnn = nn.RNN(EMBEDDING_DIM, RNN_HIDDEN_DIM, batch_first=True)\n",
    "out, h_n = rnn(x) # h_n is last hidden state\n",
    "print(\"out:\", out.shape)\n",
    "print(\"h_n:\", h_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4521, -0.0133, -0.0788,  ...,  0.2235, -0.1350,  0.2179],\n",
      "        [-0.3945,  0.0746, -0.1920,  ..., -0.1352,  0.1642,  0.1333],\n",
      "        [-0.4386, -0.4260,  0.1381,  ...,  0.0013,  0.2084,  0.0983],\n",
      "        ...,\n",
      "        [-0.2606, -0.0387,  0.0356,  ..., -0.0271, -0.0644, -0.0933],\n",
      "        [-0.0360, -0.1184,  0.1108,  ..., -0.2165,  0.3973,  0.0195],\n",
      "        [-0.2801, -0.1233, -0.0750,  ...,  0.2558,  0.1118,  0.0620]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.4521, -0.0133, -0.0788,  ...,  0.2235, -0.1350,  0.2179],\n",
      "        [-0.3945,  0.0746, -0.1920,  ..., -0.1352,  0.1642,  0.1333],\n",
      "        [-0.4386, -0.4260,  0.1381,  ...,  0.0013,  0.2084,  0.0983],\n",
      "        ...,\n",
      "        [-0.2606, -0.0387,  0.0356,  ..., -0.0271, -0.0644, -0.0933],\n",
      "        [-0.0360, -0.1184,  0.1108,  ..., -0.2165,  0.3973,  0.0195],\n",
      "        [-0.2801, -0.1233, -0.0750,  ...,  0.2558,  0.1118,  0.0620]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(out[:, -1, :])\n",
    "print(h_n.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_last_relevant_hidden(hiddens, seq_lens):\n",
    "    \"\"\"Extract and collect the last relevant\n",
    "    hidden state based on the sequence length.\"\"\"\n",
    "    seq_lens = seq_lens.long().detach().cpu().numpy() - 1\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(seq_lens):\n",
    "        out.append(hiddens[batch_index, column_index])\n",
    "    return torch.stack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last relevant hidden state\n",
    "gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens).squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "HIDDEN_DIM = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim,\n",
    "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # Initialize embeddings\n",
    "        self.embeddings = nn.Embedding(\n",
    "            embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
    "            padding_idx=padding_idx)\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(embedding_dim, rnn_hidden_dim, batch_first=True)\n",
    "\n",
    "        # FC weights\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Embed\n",
    "        x_in, seq_lens = inputs\n",
    "        x_in = self.embeddings(x_in)\n",
    "\n",
    "        # Rnn outputs\n",
    "        out, h_n = self.rnn(x_in)\n",
    "        z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
    "\n",
    "        # FC layers\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of RNN(\n",
      "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
      "  (rnn): RNN(100, 128, batch_first=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Simple RNN cell\n",
    "model = RNN(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 10\n",
    "NUM_EPOCHS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_70056/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.27532, val_loss: 1.12314, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 2 | train_loss: 1.04331, val_loss: 0.96916, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 3 | train_loss: 0.90654, val_loss: 0.85867, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 4 | train_loss: 0.80080, val_loss: 0.77539, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 5 | train_loss: 0.72175, val_loss: 0.71840, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 6 | train_loss: 0.66356, val_loss: 0.67801, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 7 | train_loss: 0.61924, val_loss: 0.64823, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 8 | train_loss: 0.58419, val_loss: 0.62539, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 9 | train_loss: 0.55528, val_loss: 0.60795, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 10 | train_loss: 0.53103, val_loss: 0.59178, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 11 | train_loss: 0.50930, val_loss: 0.58055, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 12 | train_loss: 0.49114, val_loss: 0.56864, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 13 | train_loss: 0.47483, val_loss: 0.56188, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 14 | train_loss: 0.46011, val_loss: 0.55233, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 15 | train_loss: 0.44635, val_loss: 0.54622, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 16 | train_loss: 0.43407, val_loss: 0.54204, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 17 | train_loss: 0.42202, val_loss: 0.53813, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 18 | train_loss: 0.41095, val_loss: 0.53756, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 19 | train_loss: 0.40112, val_loss: 0.53336, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 20 | train_loss: 0.39056, val_loss: 0.53496, lr: 1.00E-04, _patience: 9\n",
      "Epoch: 21 | train_loss: 0.38186, val_loss: 0.53388, lr: 1.00E-04, _patience: 8\n",
      "Epoch: 22 | train_loss: 0.37364, val_loss: 0.53543, lr: 1.00E-04, _patience: 7\n",
      "Epoch: 23 | train_loss: 0.36495, val_loss: 0.53633, lr: 1.00E-05, _patience: 6\n",
      "Epoch: 24 | train_loss: 0.34307, val_loss: 0.51650, lr: 1.00E-05, _patience: 10\n",
      "Epoch: 25 | train_loss: 0.33817, val_loss: 0.51648, lr: 1.00E-05, _patience: 10\n",
      "Epoch: 26 | train_loss: 0.33645, val_loss: 0.51749, lr: 1.00E-05, _patience: 9\n",
      "Epoch: 27 | train_loss: 0.33524, val_loss: 0.51823, lr: 1.00E-05, _patience: 8\n",
      "Epoch: 28 | train_loss: 0.33431, val_loss: 0.51916, lr: 1.00E-06, _patience: 7\n",
      "Epoch: 29 | train_loss: 0.33110, val_loss: 0.51759, lr: 1.00E-06, _patience: 6\n",
      "Epoch: 30 | train_loss: 0.33029, val_loss: 0.51746, lr: 1.00E-06, _patience: 5\n",
      "Epoch: 31 | train_loss: 0.33020, val_loss: 0.51741, lr: 1.00E-06, _patience: 4\n",
      "Epoch: 32 | train_loss: 0.33008, val_loss: 0.51740, lr: 1.00E-07, _patience: 3\n",
      "Epoch: 33 | train_loss: 0.32974, val_loss: 0.51733, lr: 1.00E-07, _patience: 2\n",
      "Epoch: 34 | train_loss: 0.32950, val_loss: 0.51733, lr: 1.00E-07, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, classes):\n",
    "    \"\"\"Per-class performance metrics.\"\"\"\n",
    "    # Performance\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "\n",
    "    # Overall performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "\n",
    "    # Per-class performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"precision\": metrics[0][i],\n",
    "            \"recall\": metrics[1][i],\n",
    "            \"f1\": metrics[2][i],\n",
    "            \"num_samples\": np.float64(metrics[3][i]),\n",
    "        }\n",
    "\n",
    "    return performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_70056/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8158669436211387,\n",
      "  \"recall\": 0.8160555555555555,\n",
      "  \"f1\": 0.8156844858613828,\n",
      "  \"num_samples\": 18000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8, 100])\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "sequence_size = 8 # words per input\n",
    "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "gru = nn.GRU(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([64, 8, 128])\n",
      "h_n: torch.Size([1, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "out, h_n = gru(x)\n",
    "print (f\"out: {out.shape}\")\n",
    "print (f\"h_n: {h_n.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi directional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "gru = nn.GRU(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM,\n",
    "             batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([64, 8, 256])\n",
      "h_n: torch.Size([2, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "out, h_n = gru(x)\n",
    "print (f\"out: {out.shape}\")\n",
    "print (f\"h_n: {h_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim,\n",
    "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        # Initialize embeddings\n",
    "        self.embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
    "                                       num_embeddings=vocab_size,\n",
    "                                       padding_idx=padding_idx)\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(embedding_dim, rnn_hidden_dim,\n",
    "                          batch_first=True, bidirectional=True)\n",
    "\n",
    "        # FC weights\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Embed\n",
    "        x_in, seq_lens = inputs\n",
    "        x_in = self.embeddings(x_in)\n",
    "\n",
    "        # Rnn outputs\n",
    "        out, h_n = self.rnn(x_in)\n",
    "        z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
    "\n",
    "        # FC layers\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of GRU(\n",
      "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
      "  (rnn): GRU(100, 128, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Simple RNN cell\n",
    "model = GRU(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model = model.to(device) # set device\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_70056/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.18282, val_loss: 0.96174, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 2 | train_loss: 0.81811, val_loss: 0.73334, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 3 | train_loss: 0.65924, val_loss: 0.64807, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 4 | train_loss: 0.58321, val_loss: 0.60503, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 5 | train_loss: 0.53376, val_loss: 0.57879, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 6 | train_loss: 0.49706, val_loss: 0.56201, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 7 | train_loss: 0.46863, val_loss: 0.55060, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 8 | train_loss: 0.44405, val_loss: 0.54394, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 9 | train_loss: 0.42358, val_loss: 0.53967, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 10 | train_loss: 0.40504, val_loss: 0.53796, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 11 | train_loss: 0.38866, val_loss: 0.53686, lr: 1.00E-04, _patience: 10\n",
      "Epoch: 12 | train_loss: 0.37373, val_loss: 0.53842, lr: 1.00E-04, _patience: 9\n",
      "Epoch: 13 | train_loss: 0.36019, val_loss: 0.54018, lr: 1.00E-04, _patience: 8\n",
      "Epoch: 14 | train_loss: 0.34752, val_loss: 0.54462, lr: 1.00E-04, _patience: 7\n",
      "Epoch: 15 | train_loss: 0.33520, val_loss: 0.54899, lr: 1.00E-05, _patience: 6\n",
      "Epoch: 16 | train_loss: 0.30903, val_loss: 0.53662, lr: 1.00E-05, _patience: 10\n",
      "Epoch: 17 | train_loss: 0.30447, val_loss: 0.53705, lr: 1.00E-05, _patience: 9\n",
      "Epoch: 18 | train_loss: 0.30246, val_loss: 0.53818, lr: 1.00E-05, _patience: 8\n",
      "Epoch: 19 | train_loss: 0.30085, val_loss: 0.53935, lr: 1.00E-05, _patience: 7\n",
      "Epoch: 20 | train_loss: 0.29949, val_loss: 0.54088, lr: 1.00E-06, _patience: 6\n",
      "Epoch: 21 | train_loss: 0.29641, val_loss: 0.53912, lr: 1.00E-06, _patience: 5\n",
      "Epoch: 22 | train_loss: 0.29531, val_loss: 0.53913, lr: 1.00E-06, _patience: 4\n",
      "Epoch: 23 | train_loss: 0.29482, val_loss: 0.53921, lr: 1.00E-06, _patience: 3\n",
      "Epoch: 24 | train_loss: 0.29498, val_loss: 0.53931, lr: 1.00E-07, _patience: 2\n",
      "Epoch: 25 | train_loss: 0.29437, val_loss: 0.53926, lr: 1.00E-07, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_70056/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8171298836449309,\n",
      "  \"recall\": 0.8173333333333334,\n",
      "  \"f1\": 0.8170294091211733,\n",
      "  \"num_samples\": 18000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "dir = Path(\"gru\")\n",
    "dir.mkdir(parents=True, exist_ok=True)\n",
    "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
    "tokenizer.save(fp=Path(dir, 'tokenizer.json'))\n",
    "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
    "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
    "    json.dump(performance, indent=2, sort_keys=False, fp=fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_distribution(y_prob, classes):\n",
    "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
    "    results = {}\n",
    "    for i, class_ in enumerate(classes):\n",
    "        results[class_] = np.float64(y_prob[i])\n",
    "    sorted_results = {k: v for k, v in sorted(\n",
    "        results.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
       "  (rnn): GRU(100, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load artifacts\n",
    "device = torch.device(\"cpu\")\n",
    "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
    "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenizer.json'))\n",
    "model = GRU(\n",
    "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
    "    rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['final tennis tournament starts next week']\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "text = \"The final tennis tournament starts next week.\"\n",
    "X = tokenizer.texts_to_sequences([preprocess(text)])\n",
    "print (tokenizer.sequences_to_texts(X))\n",
    "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
    "dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)\n",
    "dataloader = dataset.create_dataloader(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/5hv0v80j57j3rmy2pmmxvpb80000gq/T/ipykernel_70056/4106836722.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob = F.softmax(z).cpu().numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sports']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "y_prob = trainer.predict_step(dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sports\": 0.7655272483825684,\n",
      "  \"World\": 0.23432505130767822,\n",
      "  \"Business\": 0.00011062187695642933,\n",
      "  \"Sci/Tech\": 3.7027512007625774e-05\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Class distributions\n",
    "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
    "print (json.dumps(prob_dist, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "made_with_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
